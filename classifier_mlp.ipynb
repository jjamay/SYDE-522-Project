{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3874, 25), (3874, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_file = r'dataset/X.csv'\n",
    "X = pd.read_csv(X_file)\n",
    "\n",
    "Y_file = r'dataset/Y.csv'\n",
    "Y = pd.read_csv(Y_file)\n",
    "\n",
    "pd.set_option('display.max_columns', len(X.columns))\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3874, 250)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "N = 20\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('adult', None),\n",
    "    ('belongs_to_collection', HashingVectorizer(n_features=N)), \n",
    "    ('budget', None),\n",
    "    ('genres', HashingVectorizer(n_features=N)),\n",
    "    ('homepage', None),\n",
    "    ('overview', HashingVectorizer(n_features=N)),\n",
    "    ('popularity', None),\n",
    "    ('production_companies', HashingVectorizer(n_features=N)),\n",
    "    ('production_countries', HashingVectorizer(n_features=N)),\n",
    "#    ('release_date', None),\n",
    "#     ('revenue', None), \n",
    "    ('runtime', None),\n",
    "    ('spoken_languages', None),\n",
    "    ('tagline', HashingVectorizer(n_features=N)), \n",
    "    ('title', HashingVectorizer(n_features=N)),\n",
    "    ('vote_average', None),\n",
    "    ('vote_count', None),\n",
    "    ('cast', HashingVectorizer(n_features=N)),\n",
    "    ('keywords', HashingVectorizer(n_features=N)),\n",
    "    ('cast_size', None),\n",
    "    ('crew_size', None),\n",
    "    ('director', HashingVectorizer(n_features=N)),\n",
    "    ('producers', HashingVectorizer(n_features=N)),\n",
    "    ('executive_producers', HashingVectorizer(n_features=N)),\n",
    "])\n",
    "\n",
    "X.fillna('', inplace=True) # can't have nan in any of the columns\n",
    "\n",
    "features = mapper.fit_transform(X)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2711, 250), (1163, 250), (2711, 1), (1163, 1))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_ts, Y_tr, Y_ts = train_test_split(features, Y, train_size = 0.7)\n",
    "X_tr.shape, X_ts.shape, Y_tr.shape, Y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "\n",
    "X_tr_sc = scaler.transform(X_tr)\n",
    "X_ts_sc = scaler.transform(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(250, 250, 250), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "num_neurons = features.shape[1]\n",
    "num_iterations = 5000\n",
    "\n",
    "# 3 layers for now\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(num_neurons, num_neurons, num_neurons), max_iter=num_iterations)\n",
    "mlp.fit(X_tr_sc, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144 166]\n",
      " [157 696]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.48      0.46      0.47       310\n",
      "       True       0.81      0.82      0.81       853\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_ts_sc)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(Y_ts, predictions))\n",
    "\n",
    "print(classification_report(Y_ts, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "precision = accuracy_score(predictions, Y_ts) * 100\n",
    "print(\"Accuracy: {0:.2f}%\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
